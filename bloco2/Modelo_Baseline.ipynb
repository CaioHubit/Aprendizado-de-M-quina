{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069411aa-986d-48c2-9322-bb53ccf2a8fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Mohs Hardness  Specific Gravity  Refractive Index  Dispersion  \\\n",
       " 0              4.50             3.240             1.580         0.0   \n",
       " 1              2.75             3.446             1.592         0.0   \n",
       " 2              2.00             4.420             2.085         0.0   \n",
       " 3              0.00             0.000             0.000         0.0   \n",
       " 4              5.50             1.050             1.634         0.0   \n",
       " ...             ...               ...               ...         ...   \n",
       " 3107           0.00             0.000             0.000         0.0   \n",
       " 3108           0.00             0.000             0.000         0.0   \n",
       " 3109           0.00             0.000             0.000         0.0   \n",
       " 3110           0.00             0.000             0.000         0.0   \n",
       " 3111           0.00             0.000             0.000         0.0   \n",
       " \n",
       "        Molar Mass  Molar Volume  Calculated Density  \n",
       " 0      817.339002      0.123390               5.498  \n",
       " 1      435.069330      0.056083               6.439  \n",
       " 2      921.092220      0.122631               6.234  \n",
       " 3      550.019900      0.033658              13.563  \n",
       " 4      861.185368      0.112074               6.378  \n",
       " ...           ...           ...                 ...  \n",
       " 3107   677.090039      0.067308               8.349  \n",
       " 3108  1005.674169      0.280205               2.979  \n",
       " 3109  1037.626464      0.179472               4.799  \n",
       " 3110   225.663765      0.056017               3.344  \n",
       " 3111   291.060339      0.033646               7.180  \n",
       " \n",
       " [3112 rows x 7 columns],\n",
       "      Crystal Structure Diaphaneity Optical\n",
       " 0                  5.0         0.0     3.0\n",
       " 1                  4.0         3.0     3.0\n",
       " 2                  5.0         3.0     3.0\n",
       " 3                  0.0         0.0     0.0\n",
       " 4                  2.0         2.0     4.0\n",
       " ...                ...         ...     ...\n",
       " 3107               0.0         0.0     0.0\n",
       " 3108               0.0         0.0     0.0\n",
       " 3109               0.0         0.0     0.0\n",
       " 3110               0.0         0.0     0.0\n",
       " 3111               0.0         0.0     0.0\n",
       " \n",
       " [3112 rows x 3 columns])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "\n",
    "#criando o DataFrame \"df_chem\" (e talvez outros DataFrames)\n",
    "df = pd.read_csv(\"Minerals_Database3.csv\")  # Importação do dataset para ser utilizado como dataframe\n",
    "# Remoção de colunas não necessárias para o dataframe\n",
    "\n",
    "df = df.drop(['A'], axis=1)\n",
    "df = df.drop(['Name'], axis=1)\n",
    "\n",
    "dados_cat = df.reindex(df.columns[[0,2,4]], axis = 1) # Remoção de dados categóricos\n",
    "dados_categoricos = dados_cat.astype(\"category\") # Tratamento de dados para o tipo categórico\n",
    "newlist = [x for x in range(7,135)] # Range para pegarmos dados que estão em porcentagem\n",
    "porcent_df = df.reindex(df.columns[newlist], axis = 1) # Coleta dos dados de elementos em porcentagem\n",
    "df_chem = df.reindex(df.columns[[1,3,5,6,135,136,137]], axis=1) # Reindexação de um dataframe contendo apenas propriedades fisico-químicas\n",
    "df_chem, dados_categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4efc1d-df28-4ab9-a440-e178dd534ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Mohs Hardness  Specific Gravity  Refractive Index  Dispersion  \\\n",
      "3065            0.0               0.0             0.000         0.0   \n",
      "1670            0.0               0.0             0.000         0.0   \n",
      "2698            0.0               0.0             0.000         0.0   \n",
      "123             0.0               0.0             0.000         0.0   \n",
      "263             6.5               0.0             1.578         0.0   \n",
      "...             ...               ...               ...         ...   \n",
      "2064            0.0               0.0             0.000         0.0   \n",
      "2953            0.0               0.0             0.000         0.0   \n",
      "1580            0.0               0.0             0.000         0.0   \n",
      "2031            0.0               0.0             0.000         0.0   \n",
      "2932            0.0               0.0             0.000         0.0   \n",
      "\n",
      "       Molar Mass  Molar Volume  Calculated Density  \n",
      "3065   175.009500      0.033657               4.316  \n",
      "1670   523.533626      0.190498               2.281  \n",
      "2698   315.128330      0.033633               7.777  \n",
      "123    465.958940      0.033631              11.500  \n",
      "263    181.072678      0.044841               3.352  \n",
      "...           ...           ...                 ...  \n",
      "2064  1072.425603      0.101211               8.795  \n",
      "2953   951.998882      0.145752               5.421  \n",
      "1580   576.381500      0.112133               4.266  \n",
      "2031   165.471990      0.022285               6.163  \n",
      "2932   570.947048      0.089684               5.284  \n",
      "\n",
      "[2334 rows x 7 columns]\n",
      "\n",
      "      Mohs Hardness  Specific Gravity  Refractive Index  Dispersion  \\\n",
      "1603            0.0             0.000             0.000         0.0   \n",
      "1072            0.0             0.000             0.000         0.0   \n",
      "895             0.0             0.000             0.000         0.0   \n",
      "1207            0.0             0.000             0.000         0.0   \n",
      "186             5.5             0.000             0.000         0.0   \n",
      "...             ...               ...               ...         ...   \n",
      "1593            0.0             0.000             0.000         0.0   \n",
      "226             5.5             2.905             1.595         0.0   \n",
      "1985            0.0             0.000             0.000         0.0   \n",
      "1086            0.0             0.000             0.000         0.0   \n",
      "2784            0.0             0.000             0.000         0.0   \n",
      "\n",
      "       Molar Mass  Molar Volume  Calculated Density  \n",
      "1603  3305.874045      0.248162              11.057  \n",
      "1072  1290.812121      0.168314               6.365  \n",
      "895    671.460020      0.112041               4.974  \n",
      "1207   643.427090      0.100898               5.293  \n",
      "186    794.503380      0.056046              11.766  \n",
      "...           ...           ...                 ...  \n",
      "1593   269.321239      0.044969               4.971  \n",
      "226    366.475606      0.100904               3.015  \n",
      "1985   305.090720      0.078504               3.226  \n",
      "1086   390.481000      0.056070               5.780  \n",
      "2784   590.557774      0.089811               5.458  \n",
      "\n",
      "[778 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "tamanho = 0.25 # Fração de dados escolhida para treino e teste\n",
    "seed = 567\n",
    "\n",
    "i = df_chem.index\n",
    "i_treino, i_teste = train_test_split(i, test_size=tamanho, random_state = seed) #Split entre dados treino e teste\n",
    "\n",
    "df_treino = df_chem.loc[i_treino]\n",
    "df_teste = df_chem.loc[i_teste]\n",
    "\n",
    "print(df_treino)\n",
    "print()\n",
    "print(df_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef692157-58ab-48d0-a1a1-99aa857e93f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split arrays or matrices into random train and test subsets\n",
      "\n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "\n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "\n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "\n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "\n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "\n",
      "\n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "\n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "        Read more in the :ref:`User Guide <stratification>`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "\n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "\n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "\n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(train_test_split.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e0a0d11-adbf-479f-999b-3b696d1d10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo preditivo\n",
    "# Definições de atributos e targets\n",
    "nome = 'df_chem'\n",
    "atributos = [\"Specific Gravity\", \"Refractive Index\", \"Mohs Hardness\", \"Dispersion\", 'Molar Mass', 'Molar Volume', 'Calculated Density']\n",
    "target = [\"Refractive Index\"]\n",
    "\n",
    "X_treino = df_treino.reindex(atributos, axis=1).values\n",
    "y_treino = df_treino.reindex(target, axis=1).values\n",
    "X_teste = df_teste.reindex(atributos, axis=1).values\n",
    "y_teste = df_teste.reindex(target, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef83b13-975f-4c8f-b578-7361ec38444b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873 0.32643873\n",
      " 0.32643873 0.32643873 0.32643873 0.32643873]\n"
     ]
    }
   ],
   "source": [
    "# Teste modelo Baseline\n",
    "modelo_baseline = DummyRegressor()# Criação do Modelo fictício\n",
    "\n",
    "modelo_baseline.fit(X_treino, y_treino) # Treino do Modelo fictício\n",
    "\n",
    "previsao = modelo_baseline.predict(X_teste) # Previsão do modelo a partir do treino\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36dcf6aa-b595-4f7c-8146-2895c8f8f831",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    DummyRegressor is a regressor that makes predictions using\n",
      "    simple rules.\n",
      "\n",
      "    This regressor is useful as a simple baseline to compare with other\n",
      "    (real) regressors. Do not use it for real problems.\n",
      "\n",
      "    Read more in the :ref:`User Guide <dummy_estimators>`.\n",
      "\n",
      "    .. versionadded:: 0.13\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    strategy : {\"mean\", \"median\", \"quantile\", \"constant\"}, default=\"mean\"\n",
      "        Strategy to use to generate predictions.\n",
      "\n",
      "        * \"mean\": always predicts the mean of the training set\n",
      "        * \"median\": always predicts the median of the training set\n",
      "        * \"quantile\": always predicts a specified quantile of the training set,\n",
      "          provided with the quantile parameter.\n",
      "        * \"constant\": always predicts a constant value that is provided by\n",
      "          the user.\n",
      "\n",
      "    constant : int or float or array-like of shape (n_outputs,), default=None\n",
      "        The explicit constant as predicted by the \"constant\" strategy. This\n",
      "        parameter is useful only for the \"constant\" strategy.\n",
      "\n",
      "    quantile : float in [0.0, 1.0], default=None\n",
      "        The quantile to predict using the \"quantile\" strategy. A quantile of\n",
      "        0.5 corresponds to the median, while 0.0 to the minimum and 1.0 to the\n",
      "        maximum.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    constant_ : ndarray of shape (1, n_outputs)\n",
      "        Mean or median or quantile of the training targets or constant value\n",
      "        given by the user.\n",
      "\n",
      "    n_outputs_ : int\n",
      "        Number of outputs.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.dummy import DummyRegressor\n",
      "    >>> X = np.array([1.0, 2.0, 3.0, 4.0])\n",
      "    >>> y = np.array([2.0, 3.0, 5.0, 10.0])\n",
      "    >>> dummy_regr = DummyRegressor(strategy=\"mean\")\n",
      "    >>> dummy_regr.fit(X, y)\n",
      "    DummyRegressor()\n",
      "    >>> dummy_regr.predict(X)\n",
      "    array([5., 5., 5., 5.])\n",
      "    >>> dummy_regr.score(X, y)\n",
      "    0.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(DummyRegressor.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea6de26-e217-47c2-b53a-46e367f839e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A RMSE do modelo de baseline foi uma Indice Refrativo de 0.6694999657831763\n"
     ]
    }
   ],
   "source": [
    "y_verdadeiro = y_teste\n",
    "y_previsao = modelo_baseline.predict(X_teste)\n",
    "\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False) # Método da raiz quadrada do erro quadrático médio\n",
    "print(f'A RMSE do modelo de baseline foi uma Indice Refrativo de {RMSE}')\n",
    "#print(y_verdadeiro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c6e94a-a7b6-4774-9e87-7a359259ee8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error regression loss.\n",
      "\n",
      "    Read more in the :ref:`User Guide <mean_squared_error>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "        Ground truth (correct) target values.\n",
      "\n",
      "    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "        Estimated target values.\n",
      "\n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "\n",
      "    multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n",
      "        Defines aggregating of multiple output values.\n",
      "        Array-like value defines weights used to average errors.\n",
      "\n",
      "        'raw_values' :\n",
      "            Returns a full set of errors in case of multioutput input.\n",
      "\n",
      "        'uniform_average' :\n",
      "            Errors of all outputs are averaged with uniform weight.\n",
      "\n",
      "    squared : bool, default=True\n",
      "        If True returns MSE value, if False returns RMSE value.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    loss : float or ndarray of floats\n",
      "        A non-negative floating point value (the best value is 0.0), or an\n",
      "        array of floating point values, one for each individual target.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import mean_squared_error\n",
      "    >>> y_true = [3, -0.5, 2, 7]\n",
      "    >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "    >>> mean_squared_error(y_true, y_pred)\n",
      "    0.375\n",
      "    >>> y_true = [3, -0.5, 2, 7]\n",
      "    >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "    >>> mean_squared_error(y_true, y_pred, squared=False)\n",
      "    0.612...\n",
      "    >>> y_true = [[0.5, 1],[-1, 1],[7, -6]]\n",
      "    >>> y_pred = [[0, 2],[-1, 2],[8, -5]]\n",
      "    >>> mean_squared_error(y_true, y_pred)\n",
      "    0.708...\n",
      "    >>> mean_squared_error(y_true, y_pred, squared=False)\n",
      "    0.822...\n",
      "    >>> mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
      "    array([0.41666667, 1.        ])\n",
      "    >>> mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
      "    0.825...\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error.__doc__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
